{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "columns_name=[\"mpg\",\n",
        "\"cylinders\",\n",
        "\"displacement\",\n",
        "\"horsepower\",\n",
        "\"weight\",\n",
        "\"model year\",\n",
        "\"origin\",\n",
        "\"car name\"\n",
        "]"
      ],
      "metadata": {
        "id": "UWKuf1jQt-lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.horsepower"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "cLt40L5uSe8A",
        "outputId": "fd2e5eb7-9ee9-4ddf-a574-619387c4e4de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      130.0\n",
              "1      165.0\n",
              "2      150.0\n",
              "3      150.0\n",
              "4      140.0\n",
              "       ...  \n",
              "393     86.0\n",
              "394     52.0\n",
              "395     84.0\n",
              "396     79.0\n",
              "397     82.0\n",
              "Name: horsepower, Length: 398, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>horsepower</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>130.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>165.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>140.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>86.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>52.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>84.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>79.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>82.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>398 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "zCeLjM2BzK86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv(\"/content/sample_data/auto-mpg (1).csv\")\n",
        "\n",
        "# Drop the 'car name' column\n",
        "data_set = data.drop(\"car name\", axis=1)\n",
        "\n",
        "# Split into features (x) and target (y)\n",
        "x_train = data_set.drop(\"mpg\", axis=1)\n",
        "y_train = data_set[\"mpg\"]\n",
        "\n",
        "# Split into training, validation, and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
        "\n",
        "# --- Data Cleaning for 'horsepower' in ALL datasets ---\n",
        "for df in [x_train, x_val, x_test]:  # Include x_test if you will use it later\n",
        "    # Replace \"?\" with None\n",
        "    df['horsepower'] = df['horsepower'].replace(\"?\", None)\n",
        "    # Convert to numeric, coercing errors to NaN\n",
        "    df['horsepower'] = pd.to_numeric(df['horsepower'], errors='coerce')\n",
        "    # Fill NaN values with the median of 'horsepower'\n",
        "    median_hp = df['horsepower'].median()\n",
        "    df['horsepower'] = df['horsepower'].fillna(median_hp)\n",
        "    # Convert to float\n",
        "    df['horsepower'] = df['horsepower'].astype(float)\n",
        "\n",
        "# Create and fit the column transformer\n",
        "ct = make_column_transformer(\n",
        "    (StandardScaler(), [\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"model year\", \"origin\"]),\n",
        "    remainder='drop'\n",
        ")\n",
        "ct.fit(x_train)  # Fit on the training data only\n",
        "\n",
        "\n",
        "# --- Model Creation and Training ---\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(10, activation=\"linear\"),\n",
        "])\n",
        "model.compile(loss=\"mae\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"mae\"])\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epochs: 1e-3 * 10**(epochs/20))\n",
        "find_lr_history = model.fit(x_train, y_train, epochs=100, validation_data=(x_val, y_val), callbacks=[lr_scheduler])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViDkSmmizaoC",
        "outputId": "087d6373-d182-4b02-a382-5dcca4827677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 86.5830 - mae: 86.5830 - val_loss: 25.7836 - val_mae: 25.7836 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 27.0627 - mae: 27.0627 - val_loss: 20.1601 - val_mae: 20.1601 - learning_rate: 0.0011\n",
            "Epoch 3/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 18.3654 - mae: 18.3654 - val_loss: 15.6264 - val_mae: 15.6264 - learning_rate: 0.0013\n",
            "Epoch 4/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 14.5535 - mae: 14.5535 - val_loss: 14.0871 - val_mae: 14.0871 - learning_rate: 0.0014\n",
            "Epoch 5/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 12.9958 - mae: 12.9958 - val_loss: 10.7605 - val_mae: 10.7605 - learning_rate: 0.0016\n",
            "Epoch 6/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 11.2362 - mae: 11.2362 - val_loss: 11.8361 - val_mae: 11.8361 - learning_rate: 0.0018\n",
            "Epoch 7/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 11.1311 - mae: 11.1311 - val_loss: 11.0192 - val_mae: 11.0192 - learning_rate: 0.0020\n",
            "Epoch 8/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.9778 - mae: 10.9778 - val_loss: 10.2657 - val_mae: 10.2657 - learning_rate: 0.0022\n",
            "Epoch 9/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 10.4058 - mae: 10.4058 - val_loss: 11.9150 - val_mae: 11.9150 - learning_rate: 0.0025\n",
            "Epoch 10/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 12.3737 - mae: 12.3737 - val_loss: 9.8044 - val_mae: 9.8044 - learning_rate: 0.0028\n",
            "Epoch 11/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 12.3602 - mae: 12.3602 - val_loss: 15.0242 - val_mae: 15.0242 - learning_rate: 0.0032\n",
            "Epoch 12/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 13.3189 - mae: 13.3189 - val_loss: 15.7250 - val_mae: 15.7250 - learning_rate: 0.0035\n",
            "Epoch 13/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 14.8855 - mae: 14.8855 - val_loss: 19.8325 - val_mae: 19.8325 - learning_rate: 0.0040\n",
            "Epoch 14/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 18.6286 - mae: 18.6286 - val_loss: 18.2799 - val_mae: 18.2799 - learning_rate: 0.0045\n",
            "Epoch 15/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 17.8300 - mae: 17.8300 - val_loss: 12.3069 - val_mae: 12.3069 - learning_rate: 0.0050\n",
            "Epoch 16/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 14.9531 - mae: 14.9531 - val_loss: 28.4551 - val_mae: 28.4551 - learning_rate: 0.0056\n",
            "Epoch 17/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 25.5868 - mae: 25.5868 - val_loss: 18.3062 - val_mae: 18.3062 - learning_rate: 0.0063\n",
            "Epoch 18/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 16.9016 - mae: 16.9016 - val_loss: 15.7645 - val_mae: 15.7645 - learning_rate: 0.0071\n",
            "Epoch 19/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 17.3888 - mae: 17.3888 - val_loss: 32.1790 - val_mae: 32.1790 - learning_rate: 0.0079\n",
            "Epoch 20/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 31.1636 - mae: 31.1636 - val_loss: 30.5895 - val_mae: 30.5895 - learning_rate: 0.0089\n",
            "Epoch 21/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 26.7121 - mae: 26.7121 - val_loss: 13.8744 - val_mae: 13.8744 - learning_rate: 0.0100\n",
            "Epoch 22/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 15.1269 - mae: 15.1269 - val_loss: 16.7539 - val_mae: 16.7539 - learning_rate: 0.0112\n",
            "Epoch 23/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 13.6200 - mae: 13.6200 - val_loss: 9.4400 - val_mae: 9.4400 - learning_rate: 0.0126\n",
            "Epoch 24/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 10.0579 - mae: 10.0579 - val_loss: 10.1158 - val_mae: 10.1158 - learning_rate: 0.0141\n",
            "Epoch 25/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 10.0445 - mae: 10.0445 - val_loss: 7.3979 - val_mae: 7.3979 - learning_rate: 0.0158\n",
            "Epoch 26/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.0838 - mae: 9.0838 - val_loss: 7.1866 - val_mae: 7.1866 - learning_rate: 0.0178\n",
            "Epoch 27/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.2434 - mae: 8.2434 - val_loss: 7.4648 - val_mae: 7.4648 - learning_rate: 0.0200\n",
            "Epoch 28/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.9324 - mae: 8.9324 - val_loss: 9.7680 - val_mae: 9.7680 - learning_rate: 0.0224\n",
            "Epoch 29/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.3395 - mae: 10.3395 - val_loss: 9.6644 - val_mae: 9.6644 - learning_rate: 0.0251\n",
            "Epoch 30/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.8023 - mae: 8.8023 - val_loss: 7.1423 - val_mae: 7.1423 - learning_rate: 0.0282\n",
            "Epoch 31/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.2077 - mae: 9.2077 - val_loss: 11.2357 - val_mae: 11.2357 - learning_rate: 0.0316\n",
            "Epoch 32/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.6450 - mae: 10.6450 - val_loss: 6.1962 - val_mae: 6.1962 - learning_rate: 0.0355\n",
            "Epoch 33/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.3944 - mae: 8.3944 - val_loss: 5.9811 - val_mae: 5.9811 - learning_rate: 0.0398\n",
            "Epoch 34/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.8637 - mae: 7.8637 - val_loss: 9.7966 - val_mae: 9.7966 - learning_rate: 0.0447\n",
            "Epoch 35/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 13.3996 - mae: 13.3996 - val_loss: 9.8451 - val_mae: 9.8451 - learning_rate: 0.0501\n",
            "Epoch 36/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 13.3799 - mae: 13.3799 - val_loss: 15.6272 - val_mae: 15.6272 - learning_rate: 0.0562\n",
            "Epoch 37/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 12.3286 - mae: 12.3286 - val_loss: 16.2930 - val_mae: 16.2930 - learning_rate: 0.0631\n",
            "Epoch 38/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 12.9950 - mae: 12.9950 - val_loss: 5.6470 - val_mae: 5.6470 - learning_rate: 0.0708\n",
            "Epoch 39/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.9096 - mae: 7.9096 - val_loss: 6.1865 - val_mae: 6.1865 - learning_rate: 0.0794\n",
            "Epoch 40/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 14.4763 - mae: 14.4763 - val_loss: 9.5665 - val_mae: 9.5665 - learning_rate: 0.0891\n",
            "Epoch 41/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 13.3561 - mae: 13.3561 - val_loss: 10.3426 - val_mae: 10.3426 - learning_rate: 0.1000\n",
            "Epoch 42/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 13.7491 - mae: 13.7491 - val_loss: 10.8863 - val_mae: 10.8863 - learning_rate: 0.1122\n",
            "Epoch 43/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 13.1832 - mae: 13.1832 - val_loss: 10.4545 - val_mae: 10.4545 - learning_rate: 0.1259\n",
            "Epoch 44/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 12.0718 - mae: 12.0718 - val_loss: 12.3743 - val_mae: 12.3743 - learning_rate: 0.1413\n",
            "Epoch 45/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 12.4564 - mae: 12.4564 - val_loss: 9.9311 - val_mae: 9.9311 - learning_rate: 0.1585\n",
            "Epoch 46/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 12.3436 - mae: 12.3436 - val_loss: 10.8836 - val_mae: 10.8836 - learning_rate: 0.1778\n",
            "Epoch 47/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 12.1572 - mae: 12.1572 - val_loss: 11.2715 - val_mae: 11.2715 - learning_rate: 0.1995\n",
            "Epoch 48/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.9802 - mae: 9.9802 - val_loss: 6.9173 - val_mae: 6.9173 - learning_rate: 0.2239\n",
            "Epoch 49/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.3687 - mae: 6.3687 - val_loss: 9.4720 - val_mae: 9.4720 - learning_rate: 0.2512\n",
            "Epoch 50/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.4754 - mae: 8.4754 - val_loss: 6.8606 - val_mae: 6.8606 - learning_rate: 0.2818\n",
            "Epoch 51/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.2478 - mae: 7.2478 - val_loss: 6.8773 - val_mae: 6.8773 - learning_rate: 0.3162\n",
            "Epoch 52/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.9576 - mae: 6.9576 - val_loss: 8.0009 - val_mae: 8.0009 - learning_rate: 0.3548\n",
            "Epoch 53/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.4355 - mae: 7.4355 - val_loss: 7.0076 - val_mae: 7.0076 - learning_rate: 0.3981\n",
            "Epoch 54/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.9887 - mae: 6.9887 - val_loss: 6.7299 - val_mae: 6.7299 - learning_rate: 0.4467\n",
            "Epoch 55/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.5110 - mae: 6.5110 - val_loss: 6.9516 - val_mae: 6.9516 - learning_rate: 0.5012\n",
            "Epoch 56/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.4811 - mae: 6.4811 - val_loss: 8.3062 - val_mae: 8.3062 - learning_rate: 0.5623\n",
            "Epoch 57/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.1778 - mae: 7.1778 - val_loss: 6.8641 - val_mae: 6.8641 - learning_rate: 0.6310\n",
            "Epoch 58/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.6616 - mae: 6.6616 - val_loss: 7.1270 - val_mae: 7.1270 - learning_rate: 0.7079\n",
            "Epoch 59/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.7079 - mae: 6.7079 - val_loss: 6.9741 - val_mae: 6.9741 - learning_rate: 0.7943\n",
            "Epoch 60/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6.4759 - mae: 6.4759 - val_loss: 6.9470 - val_mae: 6.9470 - learning_rate: 0.8913\n",
            "Epoch 61/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.4149 - mae: 7.4149 - val_loss: 7.9021 - val_mae: 7.9021 - learning_rate: 1.0000\n",
            "Epoch 62/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.8454 - mae: 6.8454 - val_loss: 8.1019 - val_mae: 8.1019 - learning_rate: 1.1220\n",
            "Epoch 63/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.2743 - mae: 7.2743 - val_loss: 7.2289 - val_mae: 7.2289 - learning_rate: 1.2589\n",
            "Epoch 64/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.2760 - mae: 7.2760 - val_loss: 6.7267 - val_mae: 6.7267 - learning_rate: 1.4125\n",
            "Epoch 65/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.4734 - mae: 6.4734 - val_loss: 7.0176 - val_mae: 7.0176 - learning_rate: 1.5849\n",
            "Epoch 66/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.8694 - mae: 6.8694 - val_loss: 6.6910 - val_mae: 6.6910 - learning_rate: 1.7783\n",
            "Epoch 67/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.6795 - mae: 6.6795 - val_loss: 6.8847 - val_mae: 6.8847 - learning_rate: 1.9953\n",
            "Epoch 68/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.6068 - mae: 6.6068 - val_loss: 6.6969 - val_mae: 6.6969 - learning_rate: 2.2387\n",
            "Epoch 69/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.1100 - mae: 7.1100 - val_loss: 6.7039 - val_mae: 6.7039 - learning_rate: 2.5119\n",
            "Epoch 70/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.6012 - mae: 6.6012 - val_loss: 6.7770 - val_mae: 6.7770 - learning_rate: 2.8184\n",
            "Epoch 71/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.4792 - mae: 6.4792 - val_loss: 7.2463 - val_mae: 7.2463 - learning_rate: 3.1623\n",
            "Epoch 72/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.8980 - mae: 6.8980 - val_loss: 6.7861 - val_mae: 6.7861 - learning_rate: 3.5481\n",
            "Epoch 73/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.8926 - mae: 6.8926 - val_loss: 7.0496 - val_mae: 7.0496 - learning_rate: 3.9811\n",
            "Epoch 74/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.7507 - mae: 6.7507 - val_loss: 6.9852 - val_mae: 6.9852 - learning_rate: 4.4668\n",
            "Epoch 75/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.5100 - mae: 7.5100 - val_loss: 7.3573 - val_mae: 7.3573 - learning_rate: 5.0119\n",
            "Epoch 76/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.7459 - mae: 6.7459 - val_loss: 7.7652 - val_mae: 7.7652 - learning_rate: 5.6234\n",
            "Epoch 77/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.4861 - mae: 7.4861 - val_loss: 6.7754 - val_mae: 6.7754 - learning_rate: 6.3096\n",
            "Epoch 78/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.9129 - mae: 6.9129 - val_loss: 6.6902 - val_mae: 6.6902 - learning_rate: 7.0795\n",
            "Epoch 79/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.5124 - mae: 6.5124 - val_loss: 6.9109 - val_mae: 6.9109 - learning_rate: 7.9433\n",
            "Epoch 80/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.6099 - mae: 6.6099 - val_loss: 6.6927 - val_mae: 6.6927 - learning_rate: 8.9125\n",
            "Epoch 81/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.8550 - mae: 6.8550 - val_loss: 6.7793 - val_mae: 6.7793 - learning_rate: 10.0000\n",
            "Epoch 82/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.9579 - mae: 6.9579 - val_loss: 6.7340 - val_mae: 6.7340 - learning_rate: 11.2202\n",
            "Epoch 83/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.2157 - mae: 7.2157 - val_loss: 6.8347 - val_mae: 6.8347 - learning_rate: 12.5893\n",
            "Epoch 84/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.3837 - mae: 6.3837 - val_loss: 6.8595 - val_mae: 6.8595 - learning_rate: 14.1254\n",
            "Epoch 85/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.6433 - mae: 6.6433 - val_loss: 6.6893 - val_mae: 6.6893 - learning_rate: 15.8489\n",
            "Epoch 86/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.6508 - mae: 6.6508 - val_loss: 7.1830 - val_mae: 7.1830 - learning_rate: 17.7828\n",
            "Epoch 87/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.6000 - mae: 6.6000 - val_loss: 6.8985 - val_mae: 6.8985 - learning_rate: 19.9526\n",
            "Epoch 88/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.1127 - mae: 6.1127 - val_loss: 6.7017 - val_mae: 6.7017 - learning_rate: 22.3872\n",
            "Epoch 89/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.6831 - mae: 6.6831 - val_loss: 8.4736 - val_mae: 8.4736 - learning_rate: 25.1189\n",
            "Epoch 90/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.0780 - mae: 7.0780 - val_loss: 6.8745 - val_mae: 6.8745 - learning_rate: 28.1838\n",
            "Epoch 91/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.5975 - mae: 6.5975 - val_loss: 6.9625 - val_mae: 6.9625 - learning_rate: 31.6228\n",
            "Epoch 92/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.1151 - mae: 7.1151 - val_loss: 6.7978 - val_mae: 6.7978 - learning_rate: 35.4813\n",
            "Epoch 93/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.9125 - mae: 6.9125 - val_loss: 6.8314 - val_mae: 6.8314 - learning_rate: 39.8107\n",
            "Epoch 94/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.9140 - mae: 6.9140 - val_loss: 9.6023 - val_mae: 9.6023 - learning_rate: 44.6684\n",
            "Epoch 95/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.0909 - mae: 8.0909 - val_loss: 7.4227 - val_mae: 7.4227 - learning_rate: 50.1187\n",
            "Epoch 96/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.6432 - mae: 7.6432 - val_loss: 6.8408 - val_mae: 6.8408 - learning_rate: 56.2341\n",
            "Epoch 97/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.0208 - mae: 7.0208 - val_loss: 7.5903 - val_mae: 7.5903 - learning_rate: 63.0957\n",
            "Epoch 98/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.1523 - mae: 7.1523 - val_loss: 8.8372 - val_mae: 8.8372 - learning_rate: 70.7946\n",
            "Epoch 99/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.2625 - mae: 8.2625 - val_loss: 7.5885 - val_mae: 7.5885 - learning_rate: 79.4328\n",
            "Epoch 100/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.9573 - mae: 7.9573 - val_loss: 8.0715 - val_mae: 8.0715 - learning_rate: 89.1251\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OylaDFb1gge",
        "outputId": "43643df8-300b-4832-e396-c0e8f753acbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.0687 - mae: 7.0687 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6.885772705078125, 6.885772705078125]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=model.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sr18rsAB2YlI",
        "outputId": "c8e71df0-2d3c-4db0-e01b-286e449f2e73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFr_MD3CohYe",
        "outputId": "2beeb8cc-ec9b-423b-f9e7-b77378c497da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967],\n",
              "       [26.141804, 26.322361, 27.095356, 23.221958, 30.726015, 26.511293,\n",
              "        29.51046 , 25.815868, 21.831873, 26.171967]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M_eplFzWoyv_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}